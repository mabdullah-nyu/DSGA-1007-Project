{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:58:00.199881Z",
     "start_time": "2023-12-06T22:58:00.195223Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-scraping we have 2 types of data: basic restaurant details & subsequent review data. Let's clean and flatten the subsquent data frames so we can export them out into re-usable CSVs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Reviews Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:58:14.227195Z",
     "start_time": "2023-12-06T22:58:04.212720Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_reviews(file_name): \n",
    "    '''\n",
    "    load restaurant reviews data into pandas DataFrame from json file,\n",
    "    flatten the nested structure to retrieve all useful information and return the dataframe\n",
    "\n",
    "    :param feature: filename\n",
    "    '''\n",
    "    f = open(file_name) \n",
    "    data = json.load(f)\n",
    "\n",
    "    df_list = []\n",
    "    for restaurant, reviews in data.items():\n",
    "        normalized_df = pd.json_normalize(reviews)\n",
    "        normalized_df['restaurant'] = restaurant\n",
    "        filtered_df = normalized_df.dropna(axis=1, how='all')\n",
    "        df_list.append(filtered_df)\n",
    "\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Load restaurant reviews data from web scraping\n",
    "reviews = []\n",
    "path = \"{}/reviews\".format(os.getcwd())\n",
    "for file_name in os.listdir(path):\n",
    "    with open(path+'/'+file_name, \"r\") as json_file:\n",
    "        reviews.append(load_reviews(path+'/'+file_name))\n",
    "\n",
    "df_reviews = pd.concat(reviews, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:58:14.967226Z",
     "start_time": "2023-12-06T22:58:14.228848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photoCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>eliteYear</th>\n",
       "      <th>localizedDate</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment.text</th>\n",
       "      <th>comment.language</th>\n",
       "      <th>restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1012.0</td>\n",
       "      <td>321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/2/2018</td>\n",
       "      <td>5</td>\n",
       "      <td>*Tartinery is one of the food vendors at Hudso...</td>\n",
       "      <td>en</td>\n",
       "      <td>tartinery-new-york-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190.0</td>\n",
       "      <td>1421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/6/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Overall the service is very slow. We ordered 2...</td>\n",
       "      <td>en</td>\n",
       "      <td>tartinery-new-york-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117.0</td>\n",
       "      <td>294</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>10/17/2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Yum I love a place that has interesting drinks...</td>\n",
       "      <td>en</td>\n",
       "      <td>tartinery-new-york-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154.0</td>\n",
       "      <td>171</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>11/29/2021</td>\n",
       "      <td>5</td>\n",
       "      <td>I always look for a comfortable go to bar/rest...</td>\n",
       "      <td>en</td>\n",
       "      <td>tartinery-new-york-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6668.0</td>\n",
       "      <td>2143</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>4/6/2022</td>\n",
       "      <td>3</td>\n",
       "      <td>Tartinery is where you go for happy hour wine ...</td>\n",
       "      <td>en</td>\n",
       "      <td>tartinery-new-york-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331688</th>\n",
       "      <td>301.0</td>\n",
       "      <td>77</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5/21/2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Great brunch spot. Cute decor. The coffee was ...</td>\n",
       "      <td>en</td>\n",
       "      <td>brownstone-pancake-factory-edgewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331689</th>\n",
       "      <td>324.0</td>\n",
       "      <td>114</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>10/1/2022</td>\n",
       "      <td>4</td>\n",
       "      <td>An &amp;#34;All American Dinner&amp;#34; that is affor...</td>\n",
       "      <td>en</td>\n",
       "      <td>brownstone-pancake-factory-edgewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331690</th>\n",
       "      <td>24.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/10/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Went today and got the triple d buffalo chicke...</td>\n",
       "      <td>en</td>\n",
       "      <td>brownstone-pancake-factory-edgewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331691</th>\n",
       "      <td>5.0</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/7/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>We came to Brownstone as a group of 30 on a bu...</td>\n",
       "      <td>en</td>\n",
       "      <td>brownstone-pancake-factory-edgewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331692</th>\n",
       "      <td>258.0</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/13/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>They have a free valet (but please tip, folks!...</td>\n",
       "      <td>en</td>\n",
       "      <td>brownstone-pancake-factory-edgewater</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331691 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        photoCount  reviewCount  eliteYear localizedDate  rating  \\\n",
       "0           1012.0          321        NaN     11/2/2018       5   \n",
       "1            190.0         1421        NaN      8/6/2023       3   \n",
       "2            117.0          294     2023.0    10/17/2022       4   \n",
       "3            154.0          171     2023.0    11/29/2021       5   \n",
       "4           6668.0         2143     2023.0      4/6/2022       3   \n",
       "...            ...          ...        ...           ...     ...   \n",
       "331688       301.0           77     2023.0     5/21/2022       4   \n",
       "331689       324.0          114     2023.0     10/1/2022       4   \n",
       "331690        24.0           10        NaN     9/10/2023       5   \n",
       "331691         5.0           35        NaN      5/7/2023       5   \n",
       "331692       258.0          113        NaN     1/13/2023       3   \n",
       "\n",
       "                                             comment.text comment.language  \\\n",
       "0       *Tartinery is one of the food vendors at Hudso...               en   \n",
       "1       Overall the service is very slow. We ordered 2...               en   \n",
       "2       Yum I love a place that has interesting drinks...               en   \n",
       "3       I always look for a comfortable go to bar/rest...               en   \n",
       "4       Tartinery is where you go for happy hour wine ...               en   \n",
       "...                                                   ...              ...   \n",
       "331688  Great brunch spot. Cute decor. The coffee was ...               en   \n",
       "331689  An &#34;All American Dinner&#34; that is affor...               en   \n",
       "331690  Went today and got the triple d buffalo chicke...               en   \n",
       "331691  We came to Brownstone as a group of 30 on a bu...               en   \n",
       "331692  They have a free valet (but please tip, folks!...               en   \n",
       "\n",
       "                                  restaurant  \n",
       "0                      tartinery-new-york-15  \n",
       "1                      tartinery-new-york-15  \n",
       "2                      tartinery-new-york-15  \n",
       "3                      tartinery-new-york-15  \n",
       "4                      tartinery-new-york-15  \n",
       "...                                      ...  \n",
       "331688  brownstone-pancake-factory-edgewater  \n",
       "331689  brownstone-pancake-factory-edgewater  \n",
       "331690  brownstone-pancake-factory-edgewater  \n",
       "331691  brownstone-pancake-factory-edgewater  \n",
       "331692  brownstone-pancake-factory-edgewater  \n",
       "\n",
       "[331691 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews['photoCount'].fillna(0,inplace=True)\n",
    "df_reviews.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:58:14.974236Z",
     "start_time": "2023-12-06T22:58:14.968107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photoCount</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>eliteYear</th>\n",
       "      <th>localizedDate</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment.text</th>\n",
       "      <th>comment.language</th>\n",
       "      <th>restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1012.0</td>\n",
       "      <td>321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/2/2018</td>\n",
       "      <td>5</td>\n",
       "      <td>*Tartinery is one of the food vendors at Hudso...</td>\n",
       "      <td>en</td>\n",
       "      <td>tartinery-new-york-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>190.0</td>\n",
       "      <td>1421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/6/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Overall the service is very slow. We ordered 2...</td>\n",
       "      <td>en</td>\n",
       "      <td>tartinery-new-york-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117.0</td>\n",
       "      <td>294</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>10/17/2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Yum I love a place that has interesting drinks...</td>\n",
       "      <td>en</td>\n",
       "      <td>tartinery-new-york-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154.0</td>\n",
       "      <td>171</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>11/29/2021</td>\n",
       "      <td>5</td>\n",
       "      <td>I always look for a comfortable go to bar/rest...</td>\n",
       "      <td>en</td>\n",
       "      <td>tartinery-new-york-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6668.0</td>\n",
       "      <td>2143</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>4/6/2022</td>\n",
       "      <td>3</td>\n",
       "      <td>Tartinery is where you go for happy hour wine ...</td>\n",
       "      <td>en</td>\n",
       "      <td>tartinery-new-york-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331688</th>\n",
       "      <td>301.0</td>\n",
       "      <td>77</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5/21/2022</td>\n",
       "      <td>4</td>\n",
       "      <td>Great brunch spot. Cute decor. The coffee was ...</td>\n",
       "      <td>en</td>\n",
       "      <td>brownstone-pancake-factory-edgewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331689</th>\n",
       "      <td>324.0</td>\n",
       "      <td>114</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>10/1/2022</td>\n",
       "      <td>4</td>\n",
       "      <td>An &amp;#34;All American Dinner&amp;#34; that is affor...</td>\n",
       "      <td>en</td>\n",
       "      <td>brownstone-pancake-factory-edgewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331690</th>\n",
       "      <td>24.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/10/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Went today and got the triple d buffalo chicke...</td>\n",
       "      <td>en</td>\n",
       "      <td>brownstone-pancake-factory-edgewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331691</th>\n",
       "      <td>5.0</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/7/2023</td>\n",
       "      <td>5</td>\n",
       "      <td>We came to Brownstone as a group of 30 on a bu...</td>\n",
       "      <td>en</td>\n",
       "      <td>brownstone-pancake-factory-edgewater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331692</th>\n",
       "      <td>258.0</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/13/2023</td>\n",
       "      <td>3</td>\n",
       "      <td>They have a free valet (but please tip, folks!...</td>\n",
       "      <td>en</td>\n",
       "      <td>brownstone-pancake-factory-edgewater</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331693 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        photoCount  reviewCount  eliteYear localizedDate  rating  \\\n",
       "0           1012.0          321        NaN     11/2/2018       5   \n",
       "1            190.0         1421        NaN      8/6/2023       3   \n",
       "2            117.0          294     2023.0    10/17/2022       4   \n",
       "3            154.0          171     2023.0    11/29/2021       5   \n",
       "4           6668.0         2143     2023.0      4/6/2022       3   \n",
       "...            ...          ...        ...           ...     ...   \n",
       "331688       301.0           77     2023.0     5/21/2022       4   \n",
       "331689       324.0          114     2023.0     10/1/2022       4   \n",
       "331690        24.0           10        NaN     9/10/2023       5   \n",
       "331691         5.0           35        NaN      5/7/2023       5   \n",
       "331692       258.0          113        NaN     1/13/2023       3   \n",
       "\n",
       "                                             comment.text comment.language  \\\n",
       "0       *Tartinery is one of the food vendors at Hudso...               en   \n",
       "1       Overall the service is very slow. We ordered 2...               en   \n",
       "2       Yum I love a place that has interesting drinks...               en   \n",
       "3       I always look for a comfortable go to bar/rest...               en   \n",
       "4       Tartinery is where you go for happy hour wine ...               en   \n",
       "...                                                   ...              ...   \n",
       "331688  Great brunch spot. Cute decor. The coffee was ...               en   \n",
       "331689  An &#34;All American Dinner&#34; that is affor...               en   \n",
       "331690  Went today and got the triple d buffalo chicke...               en   \n",
       "331691  We came to Brownstone as a group of 30 on a bu...               en   \n",
       "331692  They have a free valet (but please tip, folks!...               en   \n",
       "\n",
       "                                  restaurant  \n",
       "0                      tartinery-new-york-15  \n",
       "1                      tartinery-new-york-15  \n",
       "2                      tartinery-new-york-15  \n",
       "3                      tartinery-new-york-15  \n",
       "4                      tartinery-new-york-15  \n",
       "...                                      ...  \n",
       "331688  brownstone-pancake-factory-edgewater  \n",
       "331689  brownstone-pancake-factory-edgewater  \n",
       "331690  brownstone-pancake-factory-edgewater  \n",
       "331691  brownstone-pancake-factory-edgewater  \n",
       "331692  brownstone-pancake-factory-edgewater  \n",
       "\n",
       "[331693 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:58:21.711118Z",
     "start_time": "2023-12-06T22:58:14.975470Z"
    }
   },
   "outputs": [],
   "source": [
    "#Transform dataframes to CSV files reusable across various analyses. \n",
    "current_directory = os.getcwd()\n",
    "file_path = os.path.join(current_directory, 'restaurant_reviews_michelin_stars.csv')\n",
    "\n",
    "df_reviews.to_csv(file_path, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Basics Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B: The review data is complex to handle due to scale; since we pulled 50 reviews per Manhattan restaurant for ~10,877 properties, GitHub restrictions won't allow us to upload a > 100MG file. \n",
    "\n",
    "Instead, we scraped review data alphabetically (reviews for Masa goes into the M folder under one M file, Rubirosa to R under one R file, etc). \n",
    "\n",
    "Now, we clean this data and amalgmate ALL reviews into a dataframe and subsquent CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:59:30.696413Z",
     "start_time": "2023-12-06T22:59:30.619268Z"
    }
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 2 column 1 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, category_df], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 48\u001b[0m df_restaurants \u001b[38;5;241m=\u001b[39m load_restaurant_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrestaurants_michelin_stars.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m, in \u001b[0;36mload_restaurant_data\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mload restaurant data into pandas DataFrame from json file (web scraping)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03massign each restaurant its official name, return the dataframe\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m:param feature: filename\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      8\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file_name) \n\u001b[0;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     10\u001b[0m df_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m restaurant, info \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp\u001b[38;5;241m.\u001b[39mread(),\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 2 column 1 (char 1)"
     ]
    }
   ],
   "source": [
    "def load_restaurant_data(file_name):\n",
    "    '''\n",
    "    load restaurant data into pandas DataFrame from json file (web scraping)\n",
    "    assign each restaurant its official name, return the dataframe\n",
    "\n",
    "    :param feature: filename\n",
    "    '''\n",
    "    f = open(file_name) \n",
    "    data = json.load(f)\n",
    "    df_list = []\n",
    "    for restaurant, info in data.items():\n",
    "        normalized_df = pd.json_normalize(info)\n",
    "        normalized_df['restaurant'] = restaurant\n",
    "        filtered_df = normalized_df.dropna(axis=1, how='all')\n",
    "        df_list.append(filtered_df)\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    df_restaurants = pd.concat(df_list, ignore_index=True)\n",
    "    return flatten_category(df_restaurants)\n",
    "\n",
    "\n",
    "def extract_titles(row):\n",
    "    '''\n",
    "    extract and return all levels of data from a nested dictionary\n",
    "\n",
    "    :param feature: 1 row of restaurant data\n",
    "    '''\n",
    "    # Extracting 'title' from each column if it is not None, otherwise using None\n",
    "    return [row[i]['title'] if row[i] is not None else None for i in range(len(row))]\n",
    "\n",
    "def flatten_category(df):\n",
    "    '''\n",
    "    extract all labels/categories of a restaurant, return the complete dataframe\n",
    "    \n",
    "    :param feature: pd dataframe\n",
    "    '''\n",
    "    new_category = pd.json_normalize(df['categories'])\n",
    "    category_df = new_category.apply(extract_titles, axis=1, result_type='expand')\n",
    "\n",
    "    # Renaming the columns\n",
    "    category_df.columns = [f'category_{i}' for i in range(new_category.shape[1])]\n",
    "\n",
    "    # Concatenate with the original dataframe if needed\n",
    "    df = pd.concat([df, category_df], axis=1)\n",
    "    return df\n",
    "\n",
    "df_restaurants = load_restaurant_data('restaurants_michelin_stars.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:54:41.746627Z",
     "start_time": "2023-12-06T22:54:41.746618Z"
    }
   },
   "outputs": [],
   "source": [
    "michelin = json.load(open(\"michelin_alias_michelin_stars.json\") )\n",
    "df_restaurants['is_michelin'] = [1 if i in michelin.values() else 0 for i in df_restaurants['restaurant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:54:41.747290Z",
     "start_time": "2023-12-06T22:54:41.747283Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exclude 8 brooklyn restaurants\n",
    "\n",
    "'''\n",
    "print(df_restaurants['is_michelin'].sum())\n",
    "print(len(michelin.values()))\n",
    "\n",
    "set_data = set(df_restaurants[df_restaurants['is_michelin']==1]['restaurant'])\n",
    "set_michelin = set(michelin.values())\n",
    "\n",
    "print(set_michelin-set_data) \n",
    "print(len(set_michelin-set_data))\n",
    "print(len(set_michelin))\n",
    "print(len(set_data))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:54:41.747797Z",
     "start_time": "2023-12-06T22:54:41.747792Z"
    }
   },
   "outputs": [],
   "source": [
    "df_restaurants.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we feature engineer to derive deeper insights & metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:54:41.748357Z",
     "start_time": "2023-12-06T22:54:41.748350Z"
    }
   },
   "outputs": [],
   "source": [
    "df_reviews_stat = df_reviews[['restaurant', 'photoCount']].groupby('restaurant').count().rename(columns={'photoCount':'reviews_cnt'})\n",
    "df_reviews_stat['elite_reviews_cnt'] = df_reviews[['restaurant', 'eliteYear']].groupby('restaurant').count()['eliteYear']\n",
    "df_reviews_stat['elite_reviews_perc'] = df_reviews_stat['elite_reviews_cnt']/df_reviews_stat['reviews_cnt']\n",
    "df_reviews_stat['user_photo_cnt_avg'] = df_reviews[['restaurant', 'photoCount']].groupby('restaurant').mean()['photoCount']\n",
    "df_reviews_stat['user_review_cnt_avg'] = df_reviews[['restaurant', 'reviewCount']].groupby('restaurant').mean()['reviewCount']\n",
    "df_reviews_stat['rating_avg'] = df_reviews[['restaurant', 'rating']].groupby('restaurant').mean()['rating']\n",
    "df_reviews_stat['rating_med'] = df_reviews[['restaurant', 'rating']].groupby('restaurant').median()['rating']\n",
    "df_reviews_stat['rating_std'] = df_reviews[['restaurant', 'rating']].groupby('restaurant').std()['rating']\n",
    "df_reviews_stat['rating_std'] = df_reviews_stat['rating_std'].fillna(0) # if we only get one review, then the std should be 0\n",
    "df_reviews_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:54:41.748789Z",
     "start_time": "2023-12-06T22:54:41.748783Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final_restaurants = pd.merge(df_restaurants, df_reviews_stat, how='inner', on='restaurant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:54:41.749343Z",
     "start_time": "2023-12-06T22:54:41.749337Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final_restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-06T22:54:41.749963Z",
     "start_time": "2023-12-06T22:54:41.749957Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CAVEAT: This CSV file is over 100MG; Github cannot support it, so we don't directly upload it. However, we use it in our analyses so if you are attempting to run code download this file by running the cells in this section. \n",
    "\"\"\"\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "file_path = os.path.join(current_directory, 'restaurant_details_michelin_stars.csv')\n",
    "\n",
    "df_final_restaurants.to_csv(file_path, index=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
